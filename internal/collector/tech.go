package collector

import (
	"context"
	"encoding/xml"
	"fmt"
	"net/http"
	"strings"
	"time"
)

// TechCollector IT/í…Œí¬ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°
type TechCollector struct {
	client *http.Client
}

// TechNews í…Œí¬ ë‰´ìŠ¤
type TechNews struct {
	Title       string    `json:"title"`
	Description string    `json:"description"`
	Link        string    `json:"link"`
	Source      string    `json:"source"`
	PubDate     time.Time `json:"pub_date"`
}

// RSS Feed êµ¬ì¡°ì²´
type RSSFeed struct {
	XMLName xml.Name `xml:"rss"`
	Channel struct {
		Title string    `xml:"title"`
		Items []RSSItem `xml:"item"`
	} `xml:"channel"`
}

type RSSItem struct {
	Title       string `xml:"title"`
	Link        string `xml:"link"`
	Description string `xml:"description"`
	PubDate     string `xml:"pubDate"`
}

func NewTechCollector() *TechCollector {
	return &TechCollector{
		client: &http.Client{Timeout: 30 * time.Second},
	}
}

// í…Œí¬ ë‰´ìŠ¤ RSS í”¼ë“œ ëª©ë¡
var techRSSFeeds = map[string]string{
	"ì§€ë””ë„·ì½”ë¦¬ì•„": "https://www.zdnet.co.kr/rss/newsall.xml",
	"ITì¡°ì„ ":   "http://it.chosun.com/rss/rss.xml",
	"ë¸”ë¡œí„°":    "https://www.bloter.net/feed",
	"í…Œí¬í¬ëŸ°ì¹˜":  "https://techcrunch.com/feed/",
}

// GetTechNews í…Œí¬ ë‰´ìŠ¤ ìˆ˜ì§‘
func (t *TechCollector) GetTechNews(ctx context.Context, limit int) ([]TechNews, error) {
	var allNews []TechNews

	for source, feedURL := range techRSSFeeds {
		news, err := t.fetchRSS(ctx, feedURL, source)
		if err != nil {
			continue // ì—ëŸ¬ ë¬´ì‹œí•˜ê³  ë‹¤ìŒ í”¼ë“œë¡œ
		}
		allNews = append(allNews, news...)
	}

	// ìµœì‹ ìˆœ ì •ë ¬ í›„ limit ì ìš©
	if len(allNews) > limit {
		allNews = allNews[:limit]
	}

	return allNews, nil
}

func (t *TechCollector) fetchRSS(ctx context.Context, feedURL, source string) ([]TechNews, error) {
	req, err := http.NewRequestWithContext(ctx, "GET", feedURL, nil)
	if err != nil {
		return nil, err
	}
	req.Header.Set("User-Agent", "TistoryBot/1.0")

	resp, err := t.client.Do(req)
	if err != nil {
		return nil, err
	}
	defer resp.Body.Close()

	var feed RSSFeed
	if err := xml.NewDecoder(resp.Body).Decode(&feed); err != nil {
		return nil, err
	}

	var news []TechNews
	for _, item := range feed.Channel.Items {
		pubDate, _ := time.Parse(time.RFC1123Z, item.PubDate)
		news = append(news, TechNews{
			Title:       item.Title,
			Description: stripHTML(item.Description),
			Link:        item.Link,
			Source:      source,
			PubDate:     pubDate,
		})
	}

	return news, nil
}

func stripHTML(s string) string {
	// ê°„ë‹¨í•œ HTML íƒœê·¸ ì œê±°
	s = strings.ReplaceAll(s, "<br>", "\n")
	s = strings.ReplaceAll(s, "<br/>", "\n")
	s = strings.ReplaceAll(s, "<br />", "\n")

	var result strings.Builder
	inTag := false
	for _, r := range s {
		if r == '<' {
			inTag = true
			continue
		}
		if r == '>' {
			inTag = false
			continue
		}
		if !inTag {
			result.WriteRune(r)
		}
	}
	return strings.TrimSpace(result.String())
}

// GenerateTechPost í…Œí¬ ë‰´ìŠ¤ í¬ìŠ¤íŠ¸ ìƒì„±
func (t *TechCollector) GenerateTechPost(news []TechNews) *Post {
	now := time.Now()
	title := fmt.Sprintf("[%s] IT/í…Œí¬ ë‰´ìŠ¤ ë¸Œë¦¬í•‘ ğŸ’»", now.Format("01/02"))

	var content strings.Builder
	content.WriteString(`<h2>ğŸ’» ì˜¤ëŠ˜ì˜ IT/í…Œí¬ ë‰´ìŠ¤</h2>
<p>ì—…ë°ì´íŠ¸: ` + now.Format("2006ë…„ 01ì›” 02ì¼ 15:04") + `</p>
`)

	for i, n := range news {
		content.WriteString(fmt.Sprintf(`
<div style="border-left: 4px solid #007bff; padding: 10px 15px; margin: 15px 0; background: #f8f9fa;">
<h3>%d. %s</h3>
<p>%s</p>
<p style="color: #666; font-size: 0.9em;">ì¶œì²˜: %s | <a href="%s" target="_blank">ì›ë¬¸ ë³´ê¸°</a></p>
</div>
`, i+1, n.Title, truncate(n.Description, 200), n.Source, n.Link))
	}

	return &Post{
		Title:    title,
		Content:  content.String(),
		Category: CategoryTech,
		Tags:     []string{"ITë‰´ìŠ¤", "í…Œí¬", "ê¸°ìˆ ", "AI", "ìŠ¤ë§ˆíŠ¸í°"},
	}
}

func truncate(s string, maxLen int) string {
	if len(s) <= maxLen {
		return s
	}
	return s[:maxLen] + "..."
}

